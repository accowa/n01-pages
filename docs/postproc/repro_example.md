# Running multiple, small-scale parallel tasks

Another scenario that requires special consideration on ARCHER2 is a need to run multiple,
small-scale parallel tasks. This may be for ensembles of perturbed models or for
investigations into the effect of varying parameter values. If each model only requires a
fraction of an ARCHER2 node then a method of launching multiple instances within each node
is required.

Slurm permits this by allowing a series of srun commands to be launched within a job
script with each subsequent command backgrounded (i.e. with the usual Unix protocol of
appending an ampersand). This will work so long as the overall resource requirement does
not exceed that requested by the job. However, the unhelpful, default behaviour on ARCHER2
is to launch each srun command on the same cores so explicit placement needs to be
generated for each srun command to achieve an effective result.

It is also usual to prepare experiment directories for each invocation in advance and to
run each srun command in a different experiment directory. The following example illustrates
such a scenario:

``` 
#!/bin/bash
#SBATCH --qos=standard
#SBATCH --job-name=nemo_test
#SBATCH --time=00:10:00
#SBATCH --nodes=1
#SBATCH --ntasks=16
#SBATCH --account=n01
#SBATCH --partition=standard
module -s restore /work/n01/shared/acc/n01_modules/ucx_env
export OMP_NUM_THREADS=1
#
cd /work/n01/n01/acc/NEMO/2021/dev_r14312_MPI_Interface/cfgs/GYRE_PISCES_ST/REPRO_4_2
srun --ntasks=8 --mem-bind=local --cpu-bind=v,map_cpu:00,0x1,0x2,0x3,0x4,0x5,0x6,0x7, ./nemo &
#
cd /work/n01/n01/acc/NEMO/2021/dev_r14312_MPI_Interface/cfgs/GYRE_PISCES_ST/REPRO_2_4
srun --ntasks=8 --mem-bind=local --cpu-bind=v,map_cpu:0x10,0x11,0x12,0x13,0x14,0x15,0x16,0x17, ./nemo &
wait
```

where two, 8-core GYRE_PISCES tests have been run simultaneously on a single node with
each correctly placed in one of the first two 16-core NUMA regions. Note also the
inclusion of the ``wait`` command after the last srun. This prevents the job-shell from
exiting until all the backgrounded tasks have completed.

Clearly, generating such scripts for many-member ensembles would be tedious. Fortunately,
an extension of the mkslurm_hetjob script (mkslurm_hetjob_ensemble) has been constructed
(thanks Mattia!) to include this capability. This allows all the same placement arguments
as the standard scripts but also accepts a series of named directories supplied to the -D
argument. A similarly distributed task is produced for each directory listed with a cd to
the appropriate directory between each srun command. Thus, an improvement on the previous
example, this time including the use of XIOS servers with each task, can be generated by:

```
dir1=/work/n01/n01/acc/NEMO/2021/dev_r14312_MPI_Interface/cfgs/GYRE_PISCES_ST/REPRO_4_2
dir2=/work/n01/n01/acc/NEMO/2021/dev_r14312_MPI_Interface/cfgs/GYRE_PISCES_ST/REPRO_2_4
/work/n01/shared/malmans/mkslurm_hetjob_ensemble -S 1 -s 8 -C 8 -g 0 m 2 -D $dir1 $dir2 
```

which produces this script ready for submission:

```
#!/bin/bash
#SBATCH --job-name=nemo_test
#SBATCH --time=00:10:00
#SBATCH --account=n01
#SBATCH --qos=standard

#SBATCH --partition=standard
#SBATCH --nodes=1
#SBATCH --ntasks=18
#SBATCH --ntasks-per-node=18
#SBATCH --ntasks-per-core=1

# Created by: mkslurm_hetjob_ensemble -S 1 -s 8 -m 2 -C 8 -g 0 -D ['/work/n01/n01/acc/NEMO/2021/dev_r14312_MPI_Interface/cfgs/GYRE_PISCES_ST/REPRO_4_2', '/work/n01/n01/acc/NEMO/2021/dev_r14312_MPI_Interface/cfgs/GYRE_PISCES_ST/REPRO_2_4'] --alternate-dirs False -N 128 -t 00:10:00 -a n01 -j nemo_test -q standard -v False
module -s restore /work/n01/shared/acc/n01_modules/ucx_env
export OMP_NUM_THREADS=1

# Ensemble 0: /work/n01/n01/acc/NEMO/2021/dev_r14312_MPI_Interface/cfgs/GYRE_PISCES_ST/REPRO_4_2
cat > "$SLURM_SUBMIT_DIR"/myscript_wrapper_0.sh << EOFB
#!/bin/ksh
#
set -A map ./xios_server.exe ./nemo
exec_map=( 0 1 1 1 1 1 1 1 1 )
#
exec \${map[\${exec_map[\$SLURM_PROCID]}]}
##
EOFB
chmod u+x "$SLURM_SUBMIT_DIR"/myscript_wrapper_0.sh
cd /work/n01/n01/acc/NEMO/2021/dev_r14312_MPI_Interface/cfgs/GYRE_PISCES_ST/REPRO_4_2 || exit
srun --mem-bind=local \
 --ntasks=9 --ntasks-per-node=9 --cpu-bind=v,mask_cpu:0x1,0x10000,0x20000,0x40000,0x80000,0x100000,0x200000,0x400000,0x800000 "$SLURM_SUBMIT_DIR"/myscript_wrapper_0.sh &
cd "$SLURM_SUBMIT_DIR" || exit

# Ensemble 1: /work/n01/n01/acc/NEMO/2021/dev_r14312_MPI_Interface/cfgs/GYRE_PISCES_ST/REPRO_2_4
cat > "$SLURM_SUBMIT_DIR"/myscript_wrapper_1.sh << EOFB
#!/bin/ksh
#
set -A map ./xios_server.exe ./nemo
exec_map=( 0 1 1 1 1 1 1 1 1 )
#
exec \${map[\${exec_map[\$SLURM_PROCID]}]}
##
EOFB
chmod u+x "$SLURM_SUBMIT_DIR"/myscript_wrapper_1.sh
cd /work/n01/n01/acc/NEMO/2021/dev_r14312_MPI_Interface/cfgs/GYRE_PISCES_ST/REPRO_2_4 || exit
srun --mem-bind=local \
 --ntasks=9 --ntasks-per-node=9 --cpu-bind=v,mask_cpu:0x100,0x1000000,0x2000000,0x4000000,0x8000000,0x10000000,0x20000000,0x40000000,0x80000000 "$SLURM_SUBMIT_DIR"/myscript_wrapper_1.sh &
cd "$SLURM_SUBMIT_DIR" || exit

wait
```

Note this script will correctly extend across multiple nodes if required and separate into
hetjob components if there is non-uniform use of the nodes.


