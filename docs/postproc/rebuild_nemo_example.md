# Running multiple rebuild_nemo commands simultaneously

For larger configurations the 'one_file' option with XIOS is not necessarily a good
choice. Too many XIOS servers trying to write to a single file can produce poor
performance. So much so that, with higher frequency output, NEMO can reach the next
archive point before the previous has been written. This can lead to a back-log of
requests and eventual out-of-memory errors. The larger configurations can also benefit
from the NetCDF4 data compression that can only be activated in 'multiple_file' mode.

In this case the post-processing task will be to rebuild the multiple strips written
by the XIOS servers into single global datasets. There is also some rechunking to do
since the default chunksizes set by XIOS are unlikely to be good choices for the 
global dataset.

Consider the example of an eORCA025 configuration with biogeochemistry. A typical 
setup could employ 16 XIOS servers and output for the biogeochemical mean fields 
may be:

```
eORCA025_MED_UKESM_1m_18560101_18561230_ptrc_T_185601-185601_0000.nc
eORCA025_MED_UKESM_1m_18560101_18561230_ptrc_T_185601-185601_0001.nc
.
.
eORCA025_MED_UKESM_1m_18560101_18561230_ptrc_T_185601-185601_0015.nc
.
.
eORCA025_MED_UKESM_1m_18560101_18561230_ptrc_T_185612-185612_0000.nc
eORCA025_MED_UKESM_1m_18560101_18561230_ptrc_T_185612-185612_0001.nc
.
.
eORCA025_MED_UKESM_1m_18560101_18561230_ptrc_T_185612-185612_0015.nc
```

with 12x16 files of monthly means for the 1 year integration. Combining each set of 16 files
into a separate monthly mean file can be done with the rebuld_nemo tool. E.g.:

```
tools/REBUILD_NEMO/rebuild_nemo -n reb.nl -p 4 -d 1 -x 64 -y 64 -z 1 -t 1 \
              eORCA025_MED_UKESM_1m_18560101_18561230_ptrc_T_185612-185612 16 
```

But, again, it will be much quicker, and a better use of the nodes, to run
multiple versions of such commands simultaneously. This is essentially the same
task as the multiple ncks invocations described previously. The main difference
being that rebuild_nemo can use OpenMP threads and it may be better to restrict
these larger tasks to one per NUMA (16 cores). This requires a 2-node solution
to process 12 months at a time. Note also that rebuild_nemo is actually a script
that takes the command-line arguments and constructs the named namelist ( not
sure why; probably whoever wrote it wasn't aware F90 has standard ways of
handling command-line arguments ).  This makes little difference other than a
need to make sure each innvocation uses a unique name for its namelist; and to
tidy up afterwards.

The complete solution is shown [here](./rebuild_nemo_script.md) but the essence 
of the controlling slurm script is this:

```
#!/bin/bash
.
#SBATCH --nodes=2
#SBATCH --ntasks=12
#SBATCH --ntasks-per-node=6
# Based on placement generated by: mkslurm -S 0 -s 0 -C 12 -c 16
export OMP_NUM_THREADS=4
.
 srun --ntasks=12 --mem-bind=local --cpu-bind=v,map_cpu:00,0x10,0x20,0x30,0x40,0x50 \
      --multi-prog tasks.conf
.
```
